{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GbfihYmQEE3p"
   },
   "source": [
    "## Applying different strategy of triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lAYsM42ZEE3r"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext skip_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "bUBKCzFOEIuP",
    "outputId": "e43cc31a-4b4f-4c88-b711-baa2f7955e0f"
   },
   "outputs": [],
   "source": [
    "%%skip $LOCAL\n",
    "#Mounting the drive\n",
    "\n",
    "import zipfile\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMfXjni6EVvw"
   },
   "outputs": [],
   "source": [
    "%%skip $LOCAL\n",
    "\n",
    "!cp -a \"/content/drive/My Drive/triplets/\" ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CrXtpk6IBmaN"
   },
   "source": [
    "Setting up tensorboard for PyTorch in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVIxPcgPBcLG"
   },
   "outputs": [],
   "source": [
    "%%skip $LOCAL\n",
    "\n",
    "!pip install -q tf-nightly-2.0-preview\n",
    "%load_ext tensorboard\n",
    "import os\n",
    "logs_base_dir = \"runs\"\n",
    "os.makedirs(logs_base_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "itWR2UmZfKh4"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-PsFY4nOe8wH"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import time\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import SVHN\n",
    "from torchvision.models import resnet18\n",
    "from typing import Union\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u9XsQmkEe42o"
   },
   "outputs": [],
   "source": [
    "from triplets.datasets import TripletSVHN\n",
    "from triplets.losses import TripletLoss, TripletSoftLoss, BatchAllTripletLoss, BatchHardTripletLoss, OnlineTripletLoss\n",
    "from triplets.metrics import mean_average_precision\n",
    "from triplets.nets import TripletNet\n",
    "from triplets.train import train\n",
    "from triplets.extractor import FeatureExtractor\n",
    "from triplets.samplers import BalancedBatchSampler\n",
    "from triplets.selectors import AllTripletSelector,HardestNegativeTripletSelector, RandomNegativeTripletSelector, \\\n",
    "                               SemihardNegativeTripletSelector # Strategies for selecting triplets within a minibatch\n",
    "from triplets.utils import freeze_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mWFBcpDTMgH0"
   },
   "outputs": [],
   "source": [
    "n_features = 512\n",
    "n_classes = 10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 100\n",
    "validation_split = 0.2\n",
    "shuffle_dataset = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YXzgWgceewZt"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "uqoPphSxeVAW",
    "outputId": "9145da26-12f6-4344-c2e1-81c8f8d819a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/train_32x32.mat\n",
      "Using downloaded and verified file: data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "dataset = SVHN(root = 'data/', download=True, split='train')\n",
    "train_size = int(0.8*len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "dataset_train, dataset_valid = random_split(dataset, [train_size, valid_size])\n",
    "dataset_test = SVHN(root = 'data/', download=True, split='test');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tmvv8Y1kJWRs"
   },
   "source": [
    "# Training model with triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMK3PXazxTeD"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_triplets = 1\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-iRwgCIpMofC"
   },
   "outputs": [],
   "source": [
    "model_base = resnet18(pretrained=True)\n",
    "model_base.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6B_d4jRlMw3a"
   },
   "source": [
    "Defining extractor using custom class to extract features from last cnn pretrained layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qguF2NEzM0JR"
   },
   "outputs": [],
   "source": [
    "extractor = FeatureExtractor(model=model_base, n_remove_layers=1, n_features=n_features, device=device)\n",
    "extracted_resnet = extractor.prepare_model()\n",
    "extracted_resnet = freeze_layers(extracted_resnet, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze all the layers besides two last ones (pooling and two convolutional blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, child in enumerate(extracted_resnet.children()):\n",
    "    if idx < 7:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7IH2ElAwxFu"
   },
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([            \n",
    " transforms.Resize(256),                    \n",
    " transforms.CenterCrop(224),                \n",
    " transforms.ToTensor(),                     \n",
    " transforms.Normalize(                      \n",
    " mean=[0.485, 0.456, 0.406],                \n",
    " std=[0.229, 0.224, 0.225]                  \n",
    " )])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with softmax triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0QSFZ0PFxNQF"
   },
   "outputs": [],
   "source": [
    "triplet_train= TripletSVHN(dataset, dataset_train.indices, dataset_valid.indices,\n",
    "                            preprocess, 'train', SEED)\n",
    "triplet_valid = TripletSVHN(dataset, dataset_train.indices, dataset_valid.indices,\n",
    "                            preprocess, 'val', SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-7BUNKDxRDI"
   },
   "outputs": [],
   "source": [
    "dataloader_train = torch.utils.data.DataLoader(triplet_train, batch_size=batch_size)\n",
    "dataloader_valid = torch.utils.data.DataLoader(triplet_valid, batch_size=batch_size)\n",
    "dataloaders = {'train': dataloader_train, 'val': dataloader_valid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUO5nexkKJiN"
   },
   "outputs": [],
   "source": [
    "model = TripletNet(extracted_resnet)\n",
    "criterion = TripletSoftLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMxMpHlHViKc"
   },
   "outputs": [],
   "source": [
    "%%skip $LOCAL\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JZb-S7sBhXuO",
    "outputId": "4828731f-4a69-4a32-ed66-74b1f6df6e4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8e7c8d2c3986>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/triplets/lib/python3.7/site-packages/triplets/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloaders, criterion, optimizer, scheduler, epochs, device, writer, model_name)\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0;31m# backward + optimize only if in training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/triplets/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/triplets/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, dataloaders, criterion, optimizer, scheduler, epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken fron the paper titled \"DEEP METRIC LEARNING USING TRIPLET NETWORK\"\n",
    "<br>\n",
    "https://arxiv.org/pdf/1412.6622.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with triplet loss provided FaceNet paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0QSFZ0PFxNQF"
   },
   "outputs": [],
   "source": [
    "triplet_train= TripletSVHN(dataset, dataset_train.indices, dataset_valid.indices,\n",
    "                            preprocess, 'train', SEED)\n",
    "triplet_valid = TripletSVHN(dataset, dataset_train.indices, dataset_valid.indices,\n",
    "                            preprocess, 'val', SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-7BUNKDxRDI"
   },
   "outputs": [],
   "source": [
    "dataloader_train = torch.utils.data.DataLoader(triplet_train, batch_size=batch_size)\n",
    "dataloader_valid = torch.utils.data.DataLoader(triplet_valid, batch_size=batch_size)\n",
    "dataloaders = {'train': dataloader_train, 'val': dataloader_valid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUO5nexkKJiN"
   },
   "outputs": [],
   "source": [
    "model = TripletNet(extracted_resnet)\n",
    "criterion = TripletLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMxMpHlHViKc"
   },
   "outputs": [],
   "source": [
    "%%skip $LOCAL\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing margin with knn model chosen in previous experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JZb-S7sBhXuO",
    "outputId": "4828731f-4a69-4a32-ed66-74b1f6df6e4b"
   },
   "outputs": [],
   "source": [
    "train(model, dataloaders, criterion, optimizer, scheduler, epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HCJB5dl0xPtB"
   },
   "source": [
    "Defining triplet datasets and dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding hard mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = FeatureExtractor(model=model_base, n_remove_layers=1, n_features=n_features, device=device)\n",
    "extracted_resnet = extractor.prepare_model()\n",
    "extracted_resnet = freeze_layers(extracted_resnet, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.container.Sequential"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(extracted_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(extracted_resnet.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_sampler = BalancedBatchSampler(dataset.labels[dataset_train.indices], n_classes=10, n_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/train_32x32.mat\n",
      "Using downloaded and verified file: data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "dataset = SVHN(root = 'data/', download=True, split='train', transform=preprocess)\n",
    "train_size = int(0.8*len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "dataset_train, dataset_valid = random_split(dataset, [train_size, valid_size])\n",
    "dataset_test = SVHN(root = 'data/', download=True, split='test', transform=preprocess);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll create mini batches by sampling labels that will be present in the mini batch and number of examples from each class\n",
    "train_batch_sampler = BalancedBatchSampler(dataset.labels[dataset_train.indices], n_classes=10, n_samples=25)\n",
    "valid_batch_sampler = BalancedBatchSampler(dataset.labels[dataset_valid.indices], n_classes=10, n_samples=25)\n",
    "\n",
    "online_train_loader = torch.utils.data.DataLoader(dataset_train, batch_sampler=train_batch_sampler)\n",
    "online_valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_sampler=valid_batch_sampler)\n",
    "\n",
    "margin = 1.\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(extracted_resnet.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "n_epochs = 20\n",
    "log_interval = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-7BUNKDxRDI"
   },
   "outputs": [],
   "source": [
    "dataloaders = {'train': online_train_loader, 'val': online_valid_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUO5nexkKJiN"
   },
   "outputs": [],
   "source": [
    "model = extracted_resnet\n",
    "criterion = OnlineTripletLoss(margin, SemihardNegativeTripletSelector(margin))\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMxMpHlHViKc"
   },
   "outputs": [],
   "source": [
    "%%skip $LOCAL\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = next(iter(online_valid_loader))\n",
    "data, labels = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JZb-S7sBhXuO",
    "outputId": "4828731f-4a69-4a32-ed66-74b1f6df6e4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8e7c8d2c3986>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/triplets/lib/python3.7/site-packages/triplets/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloaders, criterion, optimizer, scheduler, epochs, device, writer, model_name)\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0;31m# backward + optimize only if in training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/triplets/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/triplets/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, dataloaders, criterion, optimizer, scheduler, epochs, device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TripletLoss.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:triplets]",
   "language": "python",
   "name": "conda-env-triplets-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
